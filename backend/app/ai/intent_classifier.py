"""
æ„å›¾åˆ†ç±»å™¨ - å‡çº§ç‰ˆ
ä½¿ç”¨æ··åˆç­–ç•¥: è§„åˆ™åŒ¹é… + Sentence-Transformersè¯­ä¹‰ç›¸ä¼¼åº¦

ç­–ç•¥ï¼š
- ç®€å•æ„å›¾ (GREETING, CONFIRMATION) â†’ è§„åˆ™åŒ¹é… (<5ms)
- å¤æ‚æ„å›¾ â†’ Sentence-Transformersè¯­ä¹‰åŒ¹é… (~50ms)
"""

import re
import asyncio
import logging
from typing import Optional, Dict, List
from datetime import datetime
from dataclasses import dataclass, field

from sentence_transformers import SentenceTransformer, util
import torch

# Import IntentType and IntentClassification from orchestrator
from app.ai.orchestrator import IntentType, IntentClassification

logger = logging.getLogger(__name__)


@dataclass
class IntentTemplate:
    """æ„å›¾æ¨¡æ¿é…ç½®"""
    intent_type: IntentType
    examples: List[str]
    keywords: List[str] = field(default_factory=list)


class IntentClassifier:
    """
    æ··åˆæ„å›¾åˆ†ç±»å™¨

    åŠŸèƒ½ï¼š
    1. å¿«é€Ÿè§„åˆ™åŒ¹é… (ç®€å•æ„å›¾)
    2. è¯­ä¹‰ç›¸ä¼¼åº¦åŒ¹é… (å¤æ‚æ„å›¾)
    3. ç½®ä¿¡åº¦æ ¡å‡†
    4. æ€§èƒ½ç›‘æ§
    """

    def __init__(self):
        """åˆå§‹åŒ–åˆ†ç±»å™¨"""
        self.model = None  # æ‡’åŠ è½½
        self.model_name = "sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2"
        self.is_loaded = False
        self.load_lock = asyncio.Lock()

        # æ€§èƒ½æŒ‡æ ‡
        self.classification_count = 0
        self.total_inference_time = 0.0
        self.rule_match_count = 0
        self.semantic_match_count = 0

        # é¢„å®šä¹‰æ„å›¾æ¨¡æ¿
        self.intent_templates = self._initialize_templates()

        # é¢„è®¡ç®—çš„æ¨¡æ¿åµŒå…¥ (æ‡’åŠ è½½åå¡«å……)
        self.template_embeddings: Dict[IntentType, torch.Tensor] = {}

        logger.info("ğŸ¯ IntentClassifier initialized")

    def _initialize_templates(self) -> Dict[IntentType, IntentTemplate]:
        """
        åˆå§‹åŒ–æ„å›¾æ¨¡æ¿
        æ¯ä¸ªæ„å›¾åŒ…å«ï¼š
        - ç¤ºä¾‹å¥å­ (ç”¨äºè¯­ä¹‰åŒ¹é…)
        - å…³é”®è¯ (ç”¨äºè¾…åŠ©åˆ¤æ–­)
        """
        return {
            IntentType.DATA_QUERY: IntentTemplate(
                intent_type=IntentType.DATA_QUERY,
                examples=[
                    "æŸ¥è¯¢æˆ‘çš„ç¡çœ æ•°æ®",
                    "æŸ¥çœ‹æˆ‘çš„å¿ƒç‡è®°å½•",
                    "æ˜¾ç¤ºæˆ‘çš„å¥åº·æ•°æ®",
                    "æˆ‘æƒ³çœ‹çœ‹æˆ‘çš„è¿åŠ¨ç»Ÿè®¡",
                    "æˆ‘æœ€è¿‘ç¡å¾—æ€ä¹ˆæ ·",
                    "æˆ‘çš„æ­¥æ•°æ˜¯å¤šå°‘",
                    "æŸ¥çœ‹æˆ‘çš„HRVæ•°æ®",
                    "æˆ‘çš„å¥åº·æŒ‡æ ‡å¦‚ä½•"
                ],
                keywords=["æŸ¥è¯¢", "æŸ¥çœ‹", "æ˜¾ç¤º", "æ•°æ®", "è®°å½•", "ç»Ÿè®¡", "å¤šå°‘"]
            ),

            IntentType.ADVICE_REQUEST: IntentTemplate(
                intent_type=IntentType.ADVICE_REQUEST,
                examples=[
                    "ç»™æˆ‘ä¸€äº›å¥åº·å»ºè®®",
                    "æˆ‘åº”è¯¥å¦‚ä½•æ”¹å–„ç¡çœ ",
                    "å¸®æˆ‘åˆ¶å®šè¿åŠ¨è®¡åˆ’",
                    "æ€æ ·æ‰èƒ½æé«˜èƒ½é‡æ°´å¹³",
                    "å¦‚ä½•é™ä½å‹åŠ›",
                    "æ€ä¹ˆèƒ½ç¡å¾—æ›´å¥½",
                    "æœ‰ä»€ä¹ˆæ–¹æ³•å¯ä»¥æå‡ç²¾åŠ›",
                    "ç»™æˆ‘ä¸€äº›å‡å‹çš„å»ºè®®"
                ],
                keywords=["å»ºè®®", "æ€ä¹ˆ", "å¦‚ä½•", "æ€æ ·", "å¸®æˆ‘", "æ–¹æ³•", "è®¡åˆ’"]
            ),

            IntentType.EMOTIONAL_SUPPORT: IntentTemplate(
                intent_type=IntentType.EMOTIONAL_SUPPORT,
                examples=[
                    "æˆ‘æ„Ÿåˆ°å¾ˆç„¦è™‘",
                    "æœ€è¿‘å‹åŠ›å¾ˆå¤§",
                    "æˆ‘å¾ˆç–²æƒ«ï¼Œéœ€è¦å¸®åŠ©",
                    "å¿ƒæƒ…ä¸å¥½ï¼Œæƒ³èŠèŠ",
                    "æˆ‘å¾ˆéš¾å—",
                    "æ„Ÿè§‰å¾ˆç´¯ï¼Œæ’‘ä¸ä¸‹å»äº†",
                    "æœ€è¿‘å¾ˆæ²®ä¸§",
                    "æˆ‘éœ€è¦æœ‰äººç†è§£æˆ‘"
                ],
                keywords=["ç„¦è™‘", "å‹åŠ›", "ç´¯", "ç–²æƒ«", "éš¾å—", "æ²®ä¸§", "ç—›è‹¦", "æŠ‘éƒ"]
            ),

            IntentType.COMPLEX_ANALYSIS: IntentTemplate(
                intent_type=IntentType.COMPLEX_ANALYSIS,
                examples=[
                    "åˆ†ææˆ‘çš„æ•´ä½“å¥åº·çŠ¶å†µ",
                    "è¯„ä¼°æˆ‘çš„èƒ½é‡ç®¡ç†æ•ˆæœ",
                    "å¸®æˆ‘è¯Šæ–­ç¡çœ é—®é¢˜",
                    "åˆ¶å®šä¸ªæ€§åŒ–å¥åº·æ–¹æ¡ˆ",
                    "ç»¼åˆåˆ†ææˆ‘çš„å¥åº·æ•°æ®",
                    "è¯„ä¼°æˆ‘æœ€è¿‘çš„å¥åº·è¶‹åŠ¿",
                    "å¸®æˆ‘æ‰¾å‡ºå¥åº·é—®é¢˜çš„åŸå› ",
                    "å…¨é¢è¯„ä¼°æˆ‘çš„èº«ä½“çŠ¶æ€"
                ],
                keywords=["åˆ†æ", "è¯„ä¼°", "è¯Šæ–­", "æ–¹æ¡ˆ", "ç»¼åˆ", "å…¨é¢", "æ•´ä½“"]
            ),

            IntentType.HEALTH_DIAGNOSIS: IntentTemplate(
                intent_type=IntentType.HEALTH_DIAGNOSIS,
                examples=[
                    "æˆ‘çš„ç—‡çŠ¶æ˜¯ä»€ä¹ˆåŸå› ",
                    "å¸®æˆ‘è¯Šæ–­è¿™ä¸ªå¥åº·é—®é¢˜",
                    "è¿™äº›æ•°æ®è¯´æ˜æˆ‘æœ‰ä»€ä¹ˆé—®é¢˜",
                    "è¯„ä¼°æˆ‘çš„å¥åº·é£é™©",
                    "æˆ‘è¿™æ˜¯ä»€ä¹ˆç—…",
                    "ä¸ºä»€ä¹ˆæˆ‘ä¼šæœ‰è¿™äº›ç—‡çŠ¶",
                    "æˆ‘çš„èº«ä½“æœ‰ä»€ä¹ˆé—®é¢˜",
                    "è¿™ç§æƒ…å†µä¸¥é‡å—"
                ],
                keywords=["ç—‡çŠ¶", "è¯Šæ–­", "é—®é¢˜", "é£é™©", "ç—…", "ä¸¥é‡", "åŸå› "]
            )
        }

    async def _load_model(self):
        """æ‡’åŠ è½½Sentence-Transformersæ¨¡å‹"""
        async with self.load_lock:
            if self.is_loaded:
                return

            logger.info(f"ğŸ“¦ Loading Sentence-Transformers model: {self.model_name}")
            start_time = datetime.now()

            try:
                # åœ¨çº¿ç¨‹æ± ä¸­åŠ è½½æ¨¡å‹ï¼ˆé¿å…é˜»å¡äº‹ä»¶å¾ªç¯ï¼‰
                loop = asyncio.get_event_loop()
                self.model = await loop.run_in_executor(
                    None,
                    self._load_model_sync
                )

                # é¢„è®¡ç®—æ‰€æœ‰æ¨¡æ¿çš„åµŒå…¥
                await self._precompute_template_embeddings()

                load_time = (datetime.now() - start_time).total_seconds()
                logger.info(f"âœ… Model loaded in {load_time:.2f}s")

                self.is_loaded = True

            except Exception as e:
                logger.error(f"âŒ Failed to load model: {e}", exc_info=True)
                raise RuntimeError(f"Intent classifier model loading failed: {e}")

    def _load_model_sync(self) -> SentenceTransformer:
        """åŒæ­¥åŠ è½½æ¨¡å‹ï¼ˆåœ¨çº¿ç¨‹æ± ä¸­æ‰§è¡Œï¼‰"""
        return SentenceTransformer(self.model_name)

    async def _precompute_template_embeddings(self):
        """é¢„è®¡ç®—æ‰€æœ‰æ„å›¾æ¨¡æ¿çš„åµŒå…¥å‘é‡"""
        logger.info("ğŸ”„ Precomputing template embeddings...")

        loop = asyncio.get_event_loop()

        for intent_type, template in self.intent_templates.items():
            # åœ¨çº¿ç¨‹æ± ä¸­ç¼–ç 
            embeddings = await loop.run_in_executor(
                None,
                lambda examples=template.examples: self.model.encode(
                    examples,
                    convert_to_tensor=True
                )
            )

            self.template_embeddings[intent_type] = embeddings
            logger.debug(f"   âœ“ {intent_type.value}: {len(template.examples)} templates")

        logger.info(f"âœ… Precomputed {len(self.template_embeddings)} intent embeddings")

    def _classify_simple_intents(self, message: str) -> Optional[IntentClassification]:
        """
        å¿«é€Ÿè§„åˆ™åŒ¹é… (é€‚ç”¨äºç®€å•æ„å›¾)

        è¿”å› None è¡¨ç¤ºéœ€è¦ä½¿ç”¨è¯­ä¹‰æ¨¡å‹

        Args:
            message: ç”¨æˆ·æ¶ˆæ¯

        Returns:
            IntentClassification æˆ– None
        """
        msg_lower = message.lower().strip()

        # é—®å€™ (é«˜ç½®ä¿¡åº¦å…³é”®è¯)
        greeting_patterns = [
            r'^(ä½ å¥½|æ‚¨å¥½|hi|hello|æ—©ä¸Šå¥½|ä¸‹åˆå¥½|æ™šä¸Šå¥½|å—¨|hey)',
            r'^(åœ¨å—|åœ¨ä¸åœ¨|æœ‰äººå—)'
        ]

        for pattern in greeting_patterns:
            if re.search(pattern, msg_lower):
                return IntentClassification(
                    intent=IntentType.GREETING,
                    confidence=0.95,
                    requires_empathy=False,
                    requires_tools=False,
                    requires_rag=False
                )

        # ç¡®è®¤ (ç®€çŸ­å›å¤)
        if len(message) <= 6:
            confirmation_words = [
                "å¥½çš„", "å¥½", "å—¯", "æ˜¯çš„", "å¯¹", "ok",
                "è¡Œ", "å¯ä»¥", "æ²¡é—®é¢˜", "åŒæ„", "ç¡®å®š"
            ]
            if any(word in msg_lower for word in confirmation_words):
                return IntentClassification(
                    intent=IntentType.CONFIRMATION,
                    confidence=0.90,
                    requires_empathy=False,
                    requires_tools=False,
                    requires_rag=False
                )

        return None  # éœ€è¦ä½¿ç”¨è¯­ä¹‰æ¨¡å‹

    async def _classify_with_semantic_model(
        self,
        message: str,
        conversation_history: Optional[List[Dict]] = None
    ) -> IntentClassification:
        """
        ä½¿ç”¨Sentence-Transformersè¿›è¡Œè¯­ä¹‰ç›¸ä¼¼åº¦åŒ¹é…

        Args:
            message: ç”¨æˆ·æ¶ˆæ¯
            conversation_history: å¯¹è¯å†å²ï¼ˆå¯é€‰ï¼‰

        Returns:
            IntentClassification
        """
        # ç¡®ä¿æ¨¡å‹å·²åŠ è½½
        if not self.is_loaded:
            await self._load_model()

        # ç¼–ç ç”¨æˆ·æ¶ˆæ¯
        loop = asyncio.get_event_loop()
        message_embedding = await loop.run_in_executor(
            None,
            lambda: self.model.encode(message, convert_to_tensor=True)
        )

        # è®¡ç®—ä¸æ¯ä¸ªæ„å›¾æ¨¡æ¿çš„ç›¸ä¼¼åº¦
        best_intent = None
        best_score = 0.0
        intent_scores = {}

        for intent_type, template_embeddings in self.template_embeddings.items():
            # è®¡ç®—ä½™å¼¦ç›¸ä¼¼åº¦
            similarities = util.cos_sim(message_embedding, template_embeddings)[0]

            # å–æœ€å¤§ç›¸ä¼¼åº¦
            max_similarity = similarities.max().item()
            intent_scores[intent_type] = max_similarity

            if max_similarity > best_score:
                best_score = max_similarity
                best_intent = intent_type

        # å¦‚æœæ²¡æœ‰æ‰¾åˆ°åˆé€‚çš„æ„å›¾ï¼Œé»˜è®¤ä¸ºADVICE_REQUEST
        if best_intent is None:
            best_intent = IntentType.ADVICE_REQUEST
            best_score = 0.5

        # åˆ¤æ–­æ ‡å¿—ä½
        requires_empathy = best_intent == IntentType.EMOTIONAL_SUPPORT
        requires_tools = best_intent in [
            IntentType.DATA_QUERY,
            IntentType.COMPLEX_ANALYSIS,
            IntentType.HEALTH_DIAGNOSIS
        ]
        requires_rag = best_intent in [
            IntentType.ADVICE_REQUEST,
            IntentType.COMPLEX_ANALYSIS,
            IntentType.HEALTH_DIAGNOSIS
        ]

        # ç½®ä¿¡åº¦æ ¡å‡†
        confidence = self._calibrate_confidence(best_score, intent_scores)

        return IntentClassification(
            intent=best_intent,
            confidence=confidence,
            requires_empathy=requires_empathy,
            requires_tools=requires_tools,
            requires_rag=requires_rag
        )

    def _calibrate_confidence(
        self,
        best_score: float,
        all_scores: Dict[IntentType, float]
    ) -> float:
        """
        æ ¹æ®åˆ†æ•°åˆ†å¸ƒæ ¡å‡†ç½®ä¿¡åº¦

        è€ƒè™‘å› ç´ ï¼š
        - æœ€é«˜åˆ†çš„ç»å¯¹å€¼
        - æœ€é«˜åˆ†ä¸ç¬¬äºŒé«˜åˆ†çš„å·®è· (margin)

        Args:
            best_score: æœ€é«˜ç›¸ä¼¼åº¦åˆ†æ•°
            all_scores: æ‰€æœ‰æ„å›¾çš„åˆ†æ•°

        Returns:
            æ ¡å‡†åçš„ç½®ä¿¡åº¦ (0-1)
        """
        sorted_scores = sorted(all_scores.values(), reverse=True)
        top_score = sorted_scores[0]
        second_score = sorted_scores[1] if len(sorted_scores) > 1 else 0.0

        # è®¡ç®—margin (å·®è·)
        margin = top_score - second_score

        # ç½®ä¿¡åº¦å…¬å¼
        # - top_scoreè¶Šé«˜ï¼Œç½®ä¿¡åº¦è¶Šé«˜
        # - marginè¶Šå¤§ï¼Œç½®ä¿¡åº¦è¶Šé«˜ (è¯´æ˜åˆ¤æ–­è¶Šæ˜ç¡®)
        confidence = top_score * (1 + margin * 0.5)

        # é™åˆ¶èŒƒå›´
        confidence = max(0.5, min(confidence, 0.99))

        return confidence

    async def classify(
        self,
        message: str,
        conversation_history: Optional[List[Dict]] = None
    ) -> IntentClassification:
        """
        åˆ†ç±»ç”¨æˆ·æ¶ˆæ¯æ„å›¾

        ç­–ç•¥ï¼š
        1. å°è¯•è§„åˆ™åŒ¹é… (ç®€å•æ„å›¾)
        2. å¦‚æœè§„åˆ™åŒ¹é…å¤±è´¥ï¼Œä½¿ç”¨è¯­ä¹‰æ¨¡å‹

        Args:
            message: ç”¨æˆ·æ¶ˆæ¯
            conversation_history: å¯¹è¯å†å²ï¼ˆå¯é€‰ï¼Œæš‚æœªä½¿ç”¨ï¼‰

        Returns:
            IntentClassification
        """
        start_time = datetime.now()

        # 1. å°è¯•è§„åˆ™åŒ¹é…
        rule_result = self._classify_simple_intents(message)

        if rule_result:
            # è§„åˆ™åŒ¹é…æˆåŠŸ
            inference_time = (datetime.now() - start_time).total_seconds() * 1000

            self.classification_count += 1
            self.rule_match_count += 1
            self.total_inference_time += inference_time

            logger.debug(
                f"ğŸ¯ Intent (rule): {rule_result.intent.value} | "
                f"Confidence: {rule_result.confidence:.2f} | "
                f"Time: {inference_time:.1f}ms"
            )

            return rule_result

        # 2. ä½¿ç”¨è¯­ä¹‰æ¨¡å‹
        semantic_result = await self._classify_with_semantic_model(
            message,
            conversation_history
        )

        inference_time = (datetime.now() - start_time).total_seconds() * 1000

        self.classification_count += 1
        self.semantic_match_count += 1
        self.total_inference_time += inference_time

        logger.debug(
            f"ğŸ¯ Intent (semantic): {semantic_result.intent.value} | "
            f"Confidence: {semantic_result.confidence:.2f} | "
            f"Time: {inference_time:.1f}ms"
        )

        return semantic_result

    def get_stats(self) -> Dict[str, any]:
        """è·å–æ€§èƒ½ç»Ÿè®¡"""
        if self.classification_count == 0:
            return {
                "status": "not_used",
                "classification_count": 0
            }

        avg_time = self.total_inference_time / self.classification_count
        rule_percentage = (self.rule_match_count / self.classification_count) * 100
        semantic_percentage = (self.semantic_match_count / self.classification_count) * 100

        return {
            "status": "active",
            "model_loaded": self.is_loaded,
            "classification_count": self.classification_count,
            "rule_match_count": self.rule_match_count,
            "semantic_match_count": self.semantic_match_count,
            "rule_percentage": round(rule_percentage, 1),
            "semantic_percentage": round(semantic_percentage, 1),
            "avg_inference_time_ms": round(avg_time, 1),
            "total_time_seconds": round(self.total_inference_time / 1000, 2)
        }


# å…¨å±€å•ä¾‹
_global_classifier: Optional[IntentClassifier] = None


def get_intent_classifier() -> IntentClassifier:
    """è·å–å…¨å±€IntentClassifierå•ä¾‹"""
    global _global_classifier

    if _global_classifier is None:
        _global_classifier = IntentClassifier()

    return _global_classifier
