"""
å“åº”ç¼“å­˜ç³»ç»Ÿæµ‹è¯•å¥—ä»¶
æµ‹è¯•ä¸‰å±‚ç¼“å­˜æ¶æ„çš„æ­£ç¡®æ€§å’Œæ€§èƒ½
"""

import asyncio
import pytest
from datetime import datetime
from typing import List, Dict
from app.ai.response_cache import ResponseCacheManager, CacheEntry


# ============ æµ‹è¯•é…ç½® ============

@pytest.fixture
async def cache_manager():
    """åˆ›å»ºç¼“å­˜ç®¡ç†å™¨å®ä¾‹"""
    manager = ResponseCacheManager()
    await manager.initialize()
    yield manager
    # æ¸…ç†æµ‹è¯•æ•°æ®
    await manager.invalidate_user_cache("test_user_123")


# ============ L1 Redisç¼“å­˜æµ‹è¯• ============

@pytest.mark.asyncio
async def test_l1_exact_match(cache_manager: ResponseCacheManager):
    """æµ‹è¯•L1ç²¾ç¡®åŒ¹é…ç¼“å­˜"""
    user_id = "test_user_123"
    query = "æˆ‘ä»Šå¤©æ„Ÿè§‰å¾ˆç´¯"
    response = "å»ºè®®ä½ æ—©ç‚¹ä¼‘æ¯ï¼Œä¿è¯å……è¶³ç¡çœ ã€‚"

    # å†™å…¥ç¼“å­˜
    await cache_manager.set_cache(
        query=query,
        response=response,
        user_id=user_id,
        provider="phi-3.5",
        intent="energy_management",
        complexity=4,
        tokens_used=150,
        ttl=86400
    )

    # è¯»å–ç¼“å­˜ - åº”è¯¥å‘½ä¸­L1
    result = await cache_manager.get_cached_response(query, user_id)

    assert result is not None, "L1ç¼“å­˜åº”è¯¥å‘½ä¸­"
    cache_entry, cache_layer = result
    assert cache_layer == "L1", "åº”è¯¥ä»L1å±‚è¿”å›"
    assert cache_entry.response == response, "å“åº”å†…å®¹åº”è¯¥åŒ¹é…"
    assert cache_entry.hit_count >= 1, "å‘½ä¸­è®¡æ•°åº”è¯¥å¢åŠ "

    print("âœ… L1ç²¾ç¡®åŒ¹é…æµ‹è¯•é€šè¿‡")


@pytest.mark.asyncio
async def test_l1_case_insensitive(cache_manager: ResponseCacheManager):
    """æµ‹è¯•L1å¤§å°å†™ä¸æ•æ„Ÿ"""
    user_id = "test_user_123"

    # å†™å…¥å°å†™
    await cache_manager.set_cache(
        query="hello world",
        response="ä½ å¥½ï¼",
        user_id=user_id,
        provider="phi-3.5",
        intent="greeting",
        complexity=1,
        tokens_used=50,
        ttl=86400
    )

    # æŸ¥è¯¢å¤§å†™
    result = await cache_manager.get_cached_response("HELLO WORLD", user_id)

    assert result is not None, "L1åº”è¯¥å¤§å°å†™ä¸æ•æ„Ÿ"
    cache_entry, cache_layer = result
    assert cache_layer == "L1"
    assert cache_entry.response == "ä½ å¥½ï¼"

    print("âœ… L1å¤§å°å†™ä¸æ•æ„Ÿæµ‹è¯•é€šè¿‡")


@pytest.mark.asyncio
async def test_l1_whitespace_normalization(cache_manager: ResponseCacheManager):
    """æµ‹è¯•L1ç©ºç™½å­—ç¬¦å½’ä¸€åŒ–"""
    user_id = "test_user_123"

    # å†™å…¥å¸¦å¤šä½™ç©ºæ ¼
    await cache_manager.set_cache(
        query="  æˆ‘  ä»Šå¤©  å¾ˆ  ç´¯  ",
        response="å¥½å¥½ä¼‘æ¯",
        user_id=user_id,
        provider="phi-3.5",
        intent="energy_management",
        complexity=3,
        tokens_used=80,
        ttl=86400
    )

    # æŸ¥è¯¢æ­£å¸¸ç©ºæ ¼
    result = await cache_manager.get_cached_response("æˆ‘ ä»Šå¤© å¾ˆ ç´¯", user_id)

    assert result is not None, "L1åº”è¯¥å½’ä¸€åŒ–ç©ºç™½å­—ç¬¦"
    cache_entry, _ = result
    assert cache_entry.response == "å¥½å¥½ä¼‘æ¯"

    print("âœ… L1ç©ºç™½å­—ç¬¦å½’ä¸€åŒ–æµ‹è¯•é€šè¿‡")


@pytest.mark.asyncio
async def test_l1_conversation_context(cache_manager: ResponseCacheManager):
    """æµ‹è¯•L1ä¼šè¯ä¸Šä¸‹æ–‡åŒºåˆ†"""
    user_id = "test_user_123"
    query = "ç»§ç»­"

    # ä¸åŒä¸Šä¸‹æ–‡ï¼Œç›¸åŒquery
    context1 = [{"role": "user", "content": "æˆ‘æƒ³å‡è‚¥"}]
    context2 = [{"role": "user", "content": "æˆ‘æƒ³å¢è‚Œ"}]

    # å†™å…¥ä¸Šä¸‹æ–‡1çš„ç¼“å­˜
    await cache_manager.set_cache(
        query=query,
        response="å‡è‚¥éœ€è¦æ§åˆ¶é¥®é£Ÿ",
        user_id=user_id,
        provider="phi-3.5",
        intent="health_advice",
        complexity=5,
        tokens_used=120,
        conversation_history=context1,
        ttl=86400
    )

    # æŸ¥è¯¢ä¸Šä¸‹æ–‡1 - åº”è¯¥å‘½ä¸­
    result1 = await cache_manager.get_cached_response(query, user_id, context1)
    assert result1 is not None, "ä¸Šä¸‹æ–‡1åº”è¯¥å‘½ä¸­"
    assert result1[0].response == "å‡è‚¥éœ€è¦æ§åˆ¶é¥®é£Ÿ"

    # æŸ¥è¯¢ä¸Šä¸‹æ–‡2 - ä¸åº”è¯¥å‘½ä¸­L1
    result2 = await cache_manager.get_cached_response(query, user_id, context2)
    # å¯èƒ½å‘½ä¸­L2æˆ–L3ï¼Œæˆ–è€…æœªå‘½ä¸­

    print("âœ… L1ä¼šè¯ä¸Šä¸‹æ–‡åŒºåˆ†æµ‹è¯•é€šè¿‡")


# ============ L2 è¯­ä¹‰ç›¸ä¼¼åº¦æµ‹è¯• ============

@pytest.mark.asyncio
async def test_l2_semantic_similarity(cache_manager: ResponseCacheManager):
    """æµ‹è¯•L2è¯­ä¹‰ç›¸ä¼¼åº¦åŒ¹é…"""
    user_id = "test_user_123"

    # å†™å…¥åŸå§‹é—®é¢˜
    await cache_manager.set_cache(
        query="å¦‚ä½•æ”¹å–„ç¡çœ è´¨é‡ï¼Ÿ",
        response="æ”¹å–„ç¡çœ å¯ä»¥ä»ä½œæ¯è§„å¾‹ã€ç¡å‰æ”¾æ¾ã€ä¼˜åŒ–ç¯å¢ƒç­‰æ–¹é¢å…¥æ‰‹ã€‚",
        user_id=user_id,
        provider="gpt-4o-mini",
        intent="sleep_advice",
        complexity=6,
        tokens_used=200,
        ttl=604800
    )

    # ç­‰å¾…å‘é‡å†™å…¥
    await asyncio.sleep(0.5)

    # æŸ¥è¯¢ç›¸ä¼¼é—®é¢˜
    similar_queries = [
        "æ€ä¹ˆè®©ç¡çœ æ›´å¥½ï¼Ÿ",
        "ç¡çœ ä¸å¥½æ€ä¹ˆåŠï¼Ÿ",
        "å¦‚ä½•æé«˜ç¡çœ è´¨é‡",
    ]

    for similar_query in similar_queries:
        result = await cache_manager.get_cached_response(
            similar_query,
            user_id,
            similarity_threshold=0.85
        )

        if result:
            cache_entry, cache_layer = result
            assert cache_layer in ["L1", "L2", "L3"], f"ç¼“å­˜å±‚çº§é”™è¯¯: {cache_layer}"
            print(f"  âœ“ ç›¸ä¼¼é—®é¢˜ '{similar_query}' å‘½ä¸­ç¼“å­˜å±‚ {cache_layer}")
        else:
            print(f"  âœ— ç›¸ä¼¼é—®é¢˜ '{similar_query}' æœªå‘½ä¸­ç¼“å­˜")

    print("âœ… L2è¯­ä¹‰ç›¸ä¼¼åº¦æµ‹è¯•å®Œæˆ")


@pytest.mark.asyncio
async def test_l2_similarity_threshold(cache_manager: ResponseCacheManager):
    """æµ‹è¯•L2ç›¸ä¼¼åº¦é˜ˆå€¼"""
    user_id = "test_user_123"

    # å†™å…¥é—®é¢˜
    await cache_manager.set_cache(
        query="ä»Šå¤©å¤©æ°”æ€ä¹ˆæ ·ï¼Ÿ",
        response="æŠ±æ­‰ï¼Œæˆ‘æ— æ³•è·å–å®æ—¶å¤©æ°”ä¿¡æ¯ã€‚",
        user_id=user_id,
        provider="phi-3.5",
        intent="weather_query",
        complexity=2,
        tokens_used=60,
        ttl=86400
    )

    await asyncio.sleep(0.5)

    # é«˜ç›¸ä¼¼åº¦é—®é¢˜ - åº”è¯¥å‘½ä¸­
    result_high = await cache_manager.get_cached_response(
        "ä»Šå¤©çš„å¤©æ°”å¦‚ä½•ï¼Ÿ",
        user_id,
        similarity_threshold=0.85
    )
    assert result_high is not None, "é«˜ç›¸ä¼¼åº¦é—®é¢˜åº”è¯¥å‘½ä¸­"

    # ä½ç›¸ä¼¼åº¦é—®é¢˜ - ä¸åº”è¯¥å‘½ä¸­L2
    result_low = await cache_manager.get_cached_response(
        "æˆ‘ä»Šå¤©åº”è¯¥ç©¿ä»€ä¹ˆï¼Ÿ",
        user_id,
        similarity_threshold=0.92
    )
    # å¯èƒ½å‘½ä¸­L3æˆ–æœªå‘½ä¸­

    print("âœ… L2ç›¸ä¼¼åº¦é˜ˆå€¼æµ‹è¯•é€šè¿‡")


@pytest.mark.asyncio
async def test_l2_multilingual(cache_manager: ResponseCacheManager):
    """æµ‹è¯•L2å¤šè¯­è¨€æ”¯æŒ"""
    user_id = "test_user_123"

    # å†™å…¥ä¸­æ–‡é—®é¢˜
    await cache_manager.set_cache(
        query="å¦‚ä½•æé«˜å·¥ä½œæ•ˆç‡ï¼Ÿ",
        response="æé«˜å·¥ä½œæ•ˆç‡çš„æ–¹æ³•åŒ…æ‹¬æ—¶é—´ç®¡ç†ã€ä¸“æ³¨åŠ›è®­ç»ƒã€åˆç†ä¼‘æ¯ç­‰ã€‚",
        user_id=user_id,
        provider="gpt-4o-mini",
        intent="productivity_advice",
        complexity=6,
        tokens_used=180,
        ttl=604800
    )

    await asyncio.sleep(0.5)

    # æŸ¥è¯¢è‹±æ–‡ç›¸ä¼¼é—®é¢˜ï¼ˆæµ‹è¯•è·¨è¯­è¨€ï¼‰
    # æ³¨æ„ï¼šparaphrase-multilingual-MiniLM-L12-v2æ”¯æŒè·¨è¯­è¨€
    result = await cache_manager.get_cached_response(
        "How to improve work efficiency?",
        user_id,
        similarity_threshold=0.80
    )

    if result:
        print("  âœ“ è·¨è¯­è¨€åŒ¹é…æˆåŠŸ")
    else:
        print("  âœ— è·¨è¯­è¨€åŒ¹é…æœªæˆåŠŸï¼ˆå¯èƒ½éœ€è¦è°ƒæ•´é˜ˆå€¼ï¼‰")

    print("âœ… L2å¤šè¯­è¨€æµ‹è¯•å®Œæˆ")


# ============ L3 çŸ¥è¯†åº“æµ‹è¯• ============

@pytest.mark.asyncio
async def test_l3_knowledge_base(cache_manager: ResponseCacheManager):
    """æµ‹è¯•L3çŸ¥è¯†åº“å‘½ä¸­"""
    user_id = "test_user_123"

    # æŸ¥è¯¢çŸ¥è¯†åº“ä¸­çš„å¸¸è§é—®é¢˜
    knowledge_queries = [
        "ä½ å¥½",
        "è°¢è°¢",
        "å†è§",
        "ä½ æ˜¯è°ï¼Ÿ",
        "ä½ èƒ½åšä»€ä¹ˆï¼Ÿ",
    ]

    hit_count = 0
    for query in knowledge_queries:
        result = await cache_manager.get_cached_response(
            query,
            user_id,
            similarity_threshold=0.88
        )

        if result:
            cache_entry, cache_layer = result
            if cache_layer == "L3":
                hit_count += 1
                print(f"  âœ“ '{query}' å‘½ä¸­L3çŸ¥è¯†åº“")
            else:
                print(f"  âœ“ '{query}' å‘½ä¸­{cache_layer}")
        else:
            print(f"  âœ— '{query}' æœªå‘½ä¸­ç¼“å­˜")

    assert hit_count > 0, "è‡³å°‘åº”è¯¥æœ‰ä¸€ä¸ªé—®é¢˜å‘½ä¸­L3çŸ¥è¯†åº“"
    print(f"âœ… L3çŸ¥è¯†åº“æµ‹è¯•é€šè¿‡ ({hit_count}/{len(knowledge_queries)} å‘½ä¸­)")


@pytest.mark.asyncio
async def test_l3_health_knowledge(cache_manager: ResponseCacheManager):
    """æµ‹è¯•L3å¥åº·çŸ¥è¯†åº“"""
    user_id = "test_user_123"

    # æŸ¥è¯¢å¥åº·ç›¸å…³çš„å¸¸è§é—®é¢˜
    health_queries = [
        "å¦‚ä½•æ”¹å–„ç¡çœ ",
        "æ€ä¹ˆæé«˜å…ç–«åŠ›",
        "è¿åŠ¨ååº”è¯¥åƒä»€ä¹ˆ",
        "å¦‚ä½•ç¼“è§£å‹åŠ›",
    ]

    for query in health_queries:
        result = await cache_manager.get_cached_response(
            query,
            user_id,
            similarity_threshold=0.85
        )

        if result:
            cache_entry, cache_layer = result
            print(f"  âœ“ '{query}' å‘½ä¸­{cache_layer}")
            print(f"    å“åº”é¢„è§ˆ: {cache_entry.response[:50]}...")
        else:
            print(f"  âœ— '{query}' æœªå‘½ä¸­ç¼“å­˜")

    print("âœ… L3å¥åº·çŸ¥è¯†åº“æµ‹è¯•å®Œæˆ")


# ============ ç¼“å­˜å¤±æ•ˆæµ‹è¯• ============

@pytest.mark.asyncio
async def test_cache_invalidation(cache_manager: ResponseCacheManager):
    """æµ‹è¯•ç¼“å­˜å¤±æ•ˆ"""
    user_id = "test_user_123"

    # å†™å…¥å¤šæ¡ç¼“å­˜
    for i in range(5):
        await cache_manager.set_cache(
            query=f"æµ‹è¯•é—®é¢˜{i}",
            response=f"æµ‹è¯•å›ç­”{i}",
            user_id=user_id,
            provider="phi-3.5",
            intent="test",
            complexity=3,
            tokens_used=50,
            ttl=86400
        )

    # éªŒè¯ç¼“å­˜å­˜åœ¨
    result_before = await cache_manager.get_cached_response("æµ‹è¯•é—®é¢˜0", user_id)
    assert result_before is not None, "ç¼“å­˜åº”è¯¥å­˜åœ¨"

    # æ¸…ç©ºç”¨æˆ·ç¼“å­˜
    await cache_manager.invalidate_user_cache(user_id)

    # éªŒè¯ç¼“å­˜å·²æ¸…ç©º
    result_after = await cache_manager.get_cached_response("æµ‹è¯•é—®é¢˜0", user_id)
    # L1åº”è¯¥è¢«æ¸…ç©ºï¼Œä½†å¯èƒ½ä»å‘½ä¸­L3

    print("âœ… ç¼“å­˜å¤±æ•ˆæµ‹è¯•é€šè¿‡")


# ============ ç»Ÿè®¡æ•°æ®æµ‹è¯• ============

@pytest.mark.asyncio
async def test_cache_stats(cache_manager: ResponseCacheManager):
    """æµ‹è¯•ç¼“å­˜ç»Ÿè®¡"""
    user_id = "test_user_123"

    # æ‰§è¡Œä¸€äº›ç¼“å­˜æ“ä½œ
    for i in range(10):
        await cache_manager.set_cache(
            query=f"ç»Ÿè®¡æµ‹è¯•{i}",
            response=f"å›ç­”{i}",
            user_id=user_id,
            provider="phi-3.5",
            intent="test",
            complexity=3,
            tokens_used=50,
            ttl=86400
        )

        # è¯»å–å‡ æ¬¡ä»¥å¢åŠ å‘½ä¸­è®¡æ•°
        if i < 5:
            await cache_manager.get_cached_response(f"ç»Ÿè®¡æµ‹è¯•{i}", user_id)

    # è·å–ç»Ÿè®¡æ•°æ®
    stats = cache_manager.get_stats()

    assert "total_requests" in stats, "ç»Ÿè®¡åº”è¯¥åŒ…å«æ€»è¯·æ±‚æ•°"
    assert "cache_hit_rate_percent" in stats, "ç»Ÿè®¡åº”è¯¥åŒ…å«å‘½ä¸­ç‡"

    print(f"âœ… ç¼“å­˜ç»Ÿè®¡æµ‹è¯•é€šè¿‡")
    print(f"  æ€»è¯·æ±‚: {stats.get('total_requests', 0)}")
    print(f"  L1å‘½ä¸­: {stats.get('l1_hits', 0)}")
    print(f"  L2å‘½ä¸­: {stats.get('l2_hits', 0)}")
    print(f"  L3å‘½ä¸­: {stats.get('l3_hits', 0)}")
    print(f"  æœªå‘½ä¸­: {stats.get('cache_misses', 0)}")


# ============ æ€§èƒ½æµ‹è¯• ============

@pytest.mark.asyncio
async def test_cache_performance(cache_manager: ResponseCacheManager):
    """æµ‹è¯•ç¼“å­˜æ€§èƒ½"""
    import time

    user_id = "test_user_123"
    query = "æ€§èƒ½æµ‹è¯•é—®é¢˜"

    # å†™å…¥ç¼“å­˜
    await cache_manager.set_cache(
        query=query,
        response="æ€§èƒ½æµ‹è¯•å›ç­”",
        user_id=user_id,
        provider="phi-3.5",
        intent="test",
        complexity=3,
        tokens_used=50,
        ttl=86400
    )

    # æµ‹è¯•L1è¯»å–æ€§èƒ½
    l1_times = []
    for _ in range(100):
        start = time.time()
        result = await cache_manager.get_cached_response(query, user_id)
        elapsed = (time.time() - start) * 1000
        l1_times.append(elapsed)

    avg_l1_time = sum(l1_times) / len(l1_times)

    assert avg_l1_time < 10, f"L1å¹³å‡å“åº”æ—¶é—´åº”è¯¥ <10msï¼Œå®é™…: {avg_l1_time:.2f}ms"

    print(f"âœ… ç¼“å­˜æ€§èƒ½æµ‹è¯•é€šè¿‡")
    print(f"  L1å¹³å‡å“åº”æ—¶é—´: {avg_l1_time:.2f}ms")
    print(f"  L1æœ€å¿«: {min(l1_times):.2f}ms")
    print(f"  L1æœ€æ…¢: {max(l1_times):.2f}ms")


# ============ å¹¶å‘æµ‹è¯• ============

@pytest.mark.asyncio
async def test_concurrent_access(cache_manager: ResponseCacheManager):
    """æµ‹è¯•å¹¶å‘è®¿é—®"""
    user_id = "test_user_123"

    # å†™å…¥ç¼“å­˜
    await cache_manager.set_cache(
        query="å¹¶å‘æµ‹è¯•",
        response="å¹¶å‘å›ç­”",
        user_id=user_id,
        provider="phi-3.5",
        intent="test",
        complexity=3,
        tokens_used=50,
        ttl=86400
    )

    # å¹¶å‘è¯»å–
    tasks = [
        cache_manager.get_cached_response("å¹¶å‘æµ‹è¯•", user_id)
        for _ in range(50)
    ]

    results = await asyncio.gather(*tasks)

    # éªŒè¯æ‰€æœ‰è¯·æ±‚éƒ½æˆåŠŸ
    successful_reads = sum(1 for r in results if r is not None)

    assert successful_reads == 50, "æ‰€æœ‰å¹¶å‘è¯·æ±‚éƒ½åº”è¯¥æˆåŠŸ"

    print(f"âœ… å¹¶å‘è®¿é—®æµ‹è¯•é€šè¿‡ ({successful_reads}/50 æˆåŠŸ)")


# ============ è¿è¡Œæµ‹è¯• ============

if __name__ == "__main__":
    print("\n" + "="*60)
    print("ğŸ§ª å“åº”ç¼“å­˜ç³»ç»Ÿæµ‹è¯•å¥—ä»¶")
    print("="*60 + "\n")

    # è¿è¡Œæ‰€æœ‰æµ‹è¯•
    pytest.main([__file__, "-v", "-s"])
